{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsK3CqiOmiln"
      },
      "source": [
        "## installing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CXeyWHiY_ES",
        "outputId": "2969c8b2-1b89-4e67-b80e-cf6cdebebc8b"
      },
      "outputs": [],
      "source": [
        "# !pip install osmnx\n",
        "# !pip install soundscapy\n",
        "# !pip install geopandas\n",
        "# !pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QutVxV8hyGG",
        "outputId": "2ca3fcd7-1360-4933-c8df-88af73ab6f8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The system cannot find the file specified.\n"
          ]
        }
      ],
      "source": [
        "# pip install ipykernel==5.5.6 ipython==7.34.0 pandas==1.5.3 'pyzmq<25'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wNETMM5eh0aY"
      },
      "outputs": [],
      "source": [
        "# Add soundscapy to the Python path\n",
        "# import sys\n",
        "# sys.path.append('../..')\n",
        "# imports\n",
        "# %matplotlib inline\n",
        "import soundscapy as sspy\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import osmnx as ox\n",
        "from scipy import stats\n",
        "from scipy.stats import spearmanr\n",
        "import geopandas as gpd\n",
        "\n",
        "\n",
        "import warnings\n",
        "# warnings.simplefilter('ignore')\n",
        "\n",
        "%config InlineBackend.figure_format = 'svg'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgI6AQUyjCtx"
      },
      "source": [
        "# LOAD GDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "zgeTD9hDh3Ez",
        "outputId": "ffb8784e-27e9-4cdb-9b4d-16da70801a4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Renaming PAQ columns.\n",
            "Checking PAQ data quality.\n",
            "Identified 56 samples to remove.\n",
            "[95, 108, 124, 127, 146, 154, 160, 178, 186, 203, 220, 226, 255, 381, 404, 407, 431, 562, 571, 577, 586, 590, 606, 631, 659, 666, 675, 689, 694, 707, 729, 839, 846, 877, 897, 992, 1007, 1027, 1055, 1056, 1064, 1097, 1214, 1217, 1222, 1223, 1225, 1229, 1235, 1255, 1268, 1269, 1300, 1316, 1321, 1335]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LocationID</th>\n",
              "      <th>SessionID</th>\n",
              "      <th>GroupID</th>\n",
              "      <th>RecordID</th>\n",
              "      <th>Language</th>\n",
              "      <th>Lockdown</th>\n",
              "      <th>start_time</th>\n",
              "      <th>end_time</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>...</th>\n",
              "      <th>FS_Avg,arith(vacil)</th>\n",
              "      <th>I_HM_Avg,arith(iu)</th>\n",
              "      <th>Ton_HM_Avg,arith(tuHMS)</th>\n",
              "      <th>LZeq_L(dB(SPL))</th>\n",
              "      <th>LAeq_L(A)(dB(SPL))</th>\n",
              "      <th>LA10_LA90(dB(SPL))</th>\n",
              "      <th>LCeq_LAeq(dB(SPL))</th>\n",
              "      <th>LC10_LC90(dB(SPL))</th>\n",
              "      <th>RA_2D_cp(cPa)</th>\n",
              "      <th>PA(Zwicker)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>CamdenTown</td>\n",
              "      <td>CamdenTown4</td>\n",
              "      <td>CT411</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.04410</td>\n",
              "      <td>0.369</td>\n",
              "      <td>0.608</td>\n",
              "      <td>85.82</td>\n",
              "      <td>75.37</td>\n",
              "      <td>4.79</td>\n",
              "      <td>10.00</td>\n",
              "      <td>6.34</td>\n",
              "      <td>18.8</td>\n",
              "      <td>54.379887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>EustonTap</td>\n",
              "      <td>EustonTap1</td>\n",
              "      <td>ET102</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02090</td>\n",
              "      <td>0.554</td>\n",
              "      <td>0.132</td>\n",
              "      <td>79.70</td>\n",
              "      <td>70.64</td>\n",
              "      <td>5.09</td>\n",
              "      <td>7.70</td>\n",
              "      <td>4.88</td>\n",
              "      <td>16.0</td>\n",
              "      <td>38.918730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>EustonTap</td>\n",
              "      <td>EustonTap1</td>\n",
              "      <td>ET111</td>\n",
              "      <td>1300.0</td>\n",
              "      <td>English</td>\n",
              "      <td>0</td>\n",
              "      <td>28/10/2019 13:11</td>\n",
              "      <td>28/10/2019 13:14</td>\n",
              "      <td>51.5269</td>\n",
              "      <td>-0.1323</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00591</td>\n",
              "      <td>0.316</td>\n",
              "      <td>0.242</td>\n",
              "      <td>77.47</td>\n",
              "      <td>69.26</td>\n",
              "      <td>3.30</td>\n",
              "      <td>7.25</td>\n",
              "      <td>4.18</td>\n",
              "      <td>13.5</td>\n",
              "      <td>33.043909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>EustonTap</td>\n",
              "      <td>EustonTap1</td>\n",
              "      <td>ET114</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.01820</td>\n",
              "      <td>0.406</td>\n",
              "      <td>0.139</td>\n",
              "      <td>78.80</td>\n",
              "      <td>70.22</td>\n",
              "      <td>5.38</td>\n",
              "      <td>7.47</td>\n",
              "      <td>4.72</td>\n",
              "      <td>14.8</td>\n",
              "      <td>40.037874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>EustonTap</td>\n",
              "      <td>EustonTap1</td>\n",
              "      <td>ET124</td>\n",
              "      <td>1324.0</td>\n",
              "      <td>English</td>\n",
              "      <td>0</td>\n",
              "      <td>28/10/2019 14:18</td>\n",
              "      <td>28/10/2019 14:19</td>\n",
              "      <td>51.5269</td>\n",
              "      <td>-0.1323</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00761</td>\n",
              "      <td>0.383</td>\n",
              "      <td>0.201</td>\n",
              "      <td>77.56</td>\n",
              "      <td>69.89</td>\n",
              "      <td>3.25</td>\n",
              "      <td>6.87</td>\n",
              "      <td>3.12</td>\n",
              "      <td>15.1</td>\n",
              "      <td>40.247587</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 78 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     LocationID    SessionID GroupID  RecordID Language  Lockdown  \\\n",
              "95   CamdenTown  CamdenTown4   CT411       NaN      NaN         0   \n",
              "152   EustonTap   EustonTap1   ET102       NaN      NaN         0   \n",
              "168   EustonTap   EustonTap1   ET111    1300.0  English         0   \n",
              "171   EustonTap   EustonTap1   ET114       NaN      NaN         0   \n",
              "190   EustonTap   EustonTap1   ET124    1324.0  English         0   \n",
              "\n",
              "           start_time          end_time  latitude  longitude  ...  \\\n",
              "95                NaN               NaN       NaN        NaN  ...   \n",
              "152               NaN               NaN       NaN        NaN  ...   \n",
              "168  28/10/2019 13:11  28/10/2019 13:14   51.5269    -0.1323  ...   \n",
              "171               NaN               NaN       NaN        NaN  ...   \n",
              "190  28/10/2019 14:18  28/10/2019 14:19   51.5269    -0.1323  ...   \n",
              "\n",
              "     FS_Avg,arith(vacil)  I_HM_Avg,arith(iu)  Ton_HM_Avg,arith(tuHMS)  \\\n",
              "95               0.04410               0.369                    0.608   \n",
              "152              0.02090               0.554                    0.132   \n",
              "168              0.00591               0.316                    0.242   \n",
              "171              0.01820               0.406                    0.139   \n",
              "190              0.00761               0.383                    0.201   \n",
              "\n",
              "     LZeq_L(dB(SPL))  LAeq_L(A)(dB(SPL))  LA10_LA90(dB(SPL))  \\\n",
              "95             85.82               75.37                4.79   \n",
              "152            79.70               70.64                5.09   \n",
              "168            77.47               69.26                3.30   \n",
              "171            78.80               70.22                5.38   \n",
              "190            77.56               69.89                3.25   \n",
              "\n",
              "     LCeq_LAeq(dB(SPL))  LC10_LC90(dB(SPL))  RA_2D_cp(cPa)  PA(Zwicker)  \n",
              "95                10.00                6.34           18.8    54.379887  \n",
              "152                7.70                4.88           16.0    38.918730  \n",
              "168                7.25                4.18           13.5    33.043909  \n",
              "171                7.47                4.72           14.8    40.037874  \n",
              "190                6.87                3.12           15.1    40.247587  \n",
              "\n",
              "[5 rows x 78 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ssid = sspy.isd.load()\n",
        "ssid = sspy.isd.remove_lockdown(ssid)\n",
        "ssid, excl = sspy.isd.validate(ssid, allow_paq_na=False)\n",
        "excl.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "e6H70qY27zyE"
      },
      "outputs": [],
      "source": [
        "#@title create gdf\n",
        "points_lon_lat = gpd.points_from_xy(ssid['longitude'], ssid['latitude'])\n",
        "ssid_gdf = gpd.GeoDataFrame(ssid, geometry=points_lon_lat)\n",
        "# ssid_gdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xL_AeUJ59VfU"
      },
      "outputs": [],
      "source": [
        "# selecting only rows for filtered location (here location 1)\n",
        "filter_location = ['CamdenTown']\n",
        "ssid_gdf_location1 = ssid_gdf.loc[ssid['LocationID'].isin(filter_location)]\n",
        "# ssid_gdf_location1.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "G4fKTd1-5BTB"
      },
      "outputs": [],
      "source": [
        "# Group by 'LocationID' and take the first 3 rows of each group\n",
        "ssid_gdf_3_per_location = ssid_gdf.groupby('LocationID').head(3)  #.reset_index(drop=True)\n",
        "ssid_gdf_1_per_location = ssid_gdf.groupby('LocationID').head(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# maps layout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## roads width"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "form",
        "id": "FTx6TGhHS6cs"
      },
      "outputs": [],
      "source": [
        "#@title Define the mapping of road types to levels\n",
        "# used to later make destictions between roads\n",
        "road_type_mapping = {\n",
        "    'trunk': 0,\n",
        "    'trunk_link': 0,\n",
        "    'primary': 1,\n",
        "    'primary_link': 1,\n",
        "    'secondary': 2,\n",
        "    'secondary_link': 2,\n",
        "    'tertiary': 3,\n",
        "    'tertiary_link': 3,\n",
        "    'service': 3, #3to4 increased correlation by a loy\n",
        "    'residential': 4,\n",
        "    'unclassified': 4,\n",
        "    'living_street': 4,\n",
        "    'cycleway': 5,\n",
        "    'footway': 5.5,\n",
        "    'steps': 5.5,\n",
        "    'pedestrian': 5.5\n",
        "\n",
        "}\n",
        "\n",
        "road_width = {\n",
        "    'trunk': 4,\n",
        "    'trunk_link': 4,\n",
        "    'primary': 3,\n",
        "    'primary_link':3,\n",
        "    'secondary': 2,\n",
        "    'secondary_link': 2,\n",
        "    'residential': 2,\n",
        "    'tertiary': 1.5,\n",
        "    'tertiary_link': 1.5,\n",
        "    'unclassified': 1,\n",
        "    'living street': 1,\n",
        "    'unclassified': 1,\n",
        "    'service' : 1,\n",
        "    'highway': 1,\n",
        "    'unclassified': 1,\n",
        "    'living_street': 1,\n",
        "    'cycleway': 0.5,\n",
        "    'footway': 0.5,\n",
        "    'path' : 0.5,\n",
        "    'steps': 0.5,\n",
        "    'pedestrian': 0.5,\n",
        "    'track' : 0.5,\n",
        "    'corridor': 0.5\n",
        "}\n",
        "\n",
        "# Assigning a few default speed values (km/hour), fill in edges with missing `maxspeed` from OSM\n",
        "hwy_speeds = {\n",
        "    'trunk': 100,\n",
        "    'trunk_link': 100,\n",
        "    'primary': 80,\n",
        "    'primary_link': 80,\n",
        "    'secondary': 50,\n",
        "    'secondary_link': 50,\n",
        "    'tertiary': 30,\n",
        "    'tertiary_link': 30,\n",
        "    'residential': 30,\n",
        "    'unclassified': 30,\n",
        "    'living_street' : 15,\n",
        "    'cycleway': 5,\n",
        "    'footway': 5,\n",
        "    'steps': 5,\n",
        "    'pedestrian': 5\n",
        "                }\n",
        "\n",
        "# types of edges found in the dataset\n",
        "#['footway', 'unclassified', 'primary', 'residential', 'pedestrian', 'cycleway', 'service', 'tertiary', 'trunk', 'secondary', 'steps', 'path', 'primary_link']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjXL8VdYoi47",
        "outputId": "271cafd8-61c8-4586-ca92-8e911336d148"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Road Types: ['trunk', 'trunk_link', 'primary', 'primary_link', 'secondary', 'secondary_link', 'residential', 'tertiary', 'tertiary_link', 'unclassified', 'living street', 'service', 'highway', 'living_street', 'cycleway', 'footway', 'path', 'steps', 'pedestrian', 'track', 'corridor']\n",
            "Road Colors: [array([0.92156863, 0.65882353, 0.20392157]), array([0.92156863, 0.65882353, 0.20392157]), array([0.94397759, 0.75630252, 0.43137255]), array([0.94397759, 0.75630252, 0.43137255]), array([0.96638655, 0.85378151, 0.65882353]), array([0.96638655, 0.85378151, 0.65882353]), array([0.96638655, 0.85378151, 0.65882353]), array([0.97759104, 0.90252101, 0.77254902]), array([0.97759104, 0.90252101, 0.77254902]), array([0.98879552, 0.9512605 , 0.88627451]), array([0.98879552, 0.9512605 , 0.88627451]), array([0.98879552, 0.9512605 , 0.88627451]), array([0.98879552, 0.9512605 , 0.88627451]), array([0.98879552, 0.9512605 , 0.88627451]), array([1., 1., 1.]), array([1., 1., 1.]), array([1., 1., 1.]), array([1., 1., 1.]), array([1., 1., 1.]), array([1., 1., 1.]), array([1., 1., 1.])]\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.colors as mcolors\n",
        "\n",
        "# Assuming `road_width` is a predefined dictionary containing road types as keys and their respective widths as values\n",
        "\n",
        "# Extracting road types\n",
        "road_types = list(road_width.keys())\n",
        "\n",
        "# Finding the road with the maximum and minimum width\n",
        "max_width = max(road_width.values())\n",
        "min_width = min(road_width.values())\n",
        "\n",
        "# Define colors for normalization\n",
        "base_color = np.array(mcolors.to_rgb('#ffffff'))  # White\n",
        "highlight_color = np.array(mcolors.to_rgb('#eba834'))  # Orange-red\n",
        "\n",
        "# Normalize road widths\n",
        "normalized_widths = {road: (width - min_width) / (max_width - min_width) for road, width in road_width.items()}\n",
        "\n",
        "# Assigning colors to roads based on their widths\n",
        "road_colors = []\n",
        "for road, width in normalized_widths.items():\n",
        "    # Interpolating color based on the width\n",
        "    color = (1 - width) * base_color + width * highlight_color\n",
        "    road_colors.append(color)\n",
        "\n",
        "# Printing the road types and their corresponding colors\n",
        "print(\"Road Types:\", road_types)\n",
        "print(\"Road Colors:\", road_colors)\n",
        "\n",
        "# Creating a dictionary mapping road types to their colors\n",
        "road_type_colors = dict(zip(road_types, road_colors))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vaXVaqUqCQO"
      },
      "source": [
        "## tags OSM data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Fa3U7zZJPb69"
      },
      "outputs": [],
      "source": [
        "# tags for the OSM data\n",
        "tags_buildings = {'building': True}\n",
        "\n",
        "tags_natural = {'natural': ['fell', 'grassland', 'health', 'scrub', 'wood' ]} # {'natural': True }\n",
        "tags_landuse = {'landuse':[ 'grass','greenfield']}\n",
        "tags_parks = {'leisure':[ 'nature_reserve','park', 'track', 'garden' ]}\n",
        "tags_water = {'natural': [ 'water' ]}\n",
        "tags_wetland = {'natural': [ 'wetland' ]}\n",
        "tags_tree = {'natural':[ 'grassland', 'tree', 'wood'] }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CM717fvEZz9U"
      },
      "source": [
        "# main function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0FCsnwpynKw4"
      },
      "outputs": [],
      "source": [
        "#get 5 random points from gdf\n",
        "import random\n",
        "random_rows = ssid_gdf.sample(n=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## def load osm data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8vl6Fmx7mFe9"
      },
      "outputs": [],
      "source": [
        "#@title def load osm data\n",
        "def load_osm_data(point, tags, size):\n",
        "    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "    try:\n",
        "        data = ox.features_from_point(point, tags, dist=size)\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f'Error loading {tags} data: {e}')\n",
        "        return None\n",
        "    warnings.resetwarnings()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## def create bounding box from centerpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "eqjmTaEiZCSr"
      },
      "outputs": [],
      "source": [
        "#@title def create bounding box from centerpoint\n",
        "import math\n",
        "import shapely.geometry as geometry\n",
        "\n",
        "def degrees_to_meters(latitude):\n",
        "    # Earth radius in meters\n",
        "    earth_radius = 6378137\n",
        "\n",
        "    # Convert latitude from degrees to radians\n",
        "    lat_rad = math.radians(latitude)\n",
        "\n",
        "    # Calculate the length of one degree of latitude in meters\n",
        "    lat_length = math.cos(lat_rad) * math.pi * earth_radius / 180\n",
        "\n",
        "    # Calculate the length of one degree of longitude in meters\n",
        "    lon_length = math.pi * earth_radius / 180\n",
        "\n",
        "    return lat_length, lon_length\n",
        "\n",
        "\n",
        "def meters_to_degrees(point, meters):\n",
        "    latitude = point[0]\n",
        "    longitude = point[1]\n",
        "     # Get the length of one degree of latitude and longitude\n",
        "    lat_length, lon_length = degrees_to_meters(latitude)\n",
        "\n",
        "    # Convert meters to degrees\n",
        "    lat_degrees = meters / lat_length\n",
        "    lon_degrees = meters / lon_length\n",
        "\n",
        "    return lat_degrees, lon_degrees\n",
        "\n",
        "\n",
        "def get_bounding_box(center_point, meters):\n",
        "    latitude = center_point[0]\n",
        "    longitude = center_point[1]\n",
        "\n",
        "    # Calculate how many degrees correspond to the given meters\n",
        "    lat_degrees, lon_degrees = meters_to_degrees(center_point, meters)\n",
        "\n",
        "    # Calculate the bounding box coordinates\n",
        "    y_min = latitude - lon_degrees\n",
        "    y_max = latitude + lon_degrees\n",
        "    x_min = longitude - lat_degrees\n",
        "    x_max = longitude + lat_degrees\n",
        "\n",
        "    # Create a shapely polygon representing the bounding box\n",
        "    bounding_box = geometry.box(x_min, y_min, x_max, y_max)\n",
        "\n",
        "    # Return the bounding box and its coordinates\n",
        "    return bounding_box, [y_max, y_min, x_max, x_min]\n",
        "\n",
        "# Example usage:\n",
        "# center_point = (40.730610, -73.935242)  # Example center point (latitude, longitude)\n",
        "meters = 300  # Example distance in meters\n",
        "\n",
        "# bounding_box, bbox_coordinates = get_bounding_box(center_point, meters)\n",
        "# print(\"Bounding Box Coordinates:\", bbox_coordinates)\n",
        "# print(\"Bounding Box WKT:\", bounding_box.wkt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## def create scalebar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WtaZRiNYHhJF"
      },
      "outputs": [],
      "source": [
        "#@title def create scalebar\n",
        "from shapely.geometry import box\n",
        "\n",
        "def create_scale_bar(bbox_coordinates, center_point, meters=4):\n",
        "    \"\"\"\n",
        "    Generates a scale bar represented by a list of shapely polygons\n",
        "    within the given bounding box coordinates.\n",
        "\n",
        "    Parameters:\n",
        "    - bbox_coordinates (list): A list of bounding box coordinates [y_max, y_min, x_max, x_min].\n",
        "    - meters (float): Length in meters for the scale bar.\n",
        "\n",
        "    Returns:\n",
        "    - scalebar_list (list): List of shapely polygons representing the scale bar.\n",
        "    - bbox_coords_updated (list): Updated bounding box coordinates.\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert meters to degrees for latitude and longitude\n",
        "    lat_degrees, lon_degrees = meters_to_degrees(center_point, meters)\n",
        "\n",
        "    # Extracting the lower right corner coordinates\n",
        "    y_min, x_min = bbox_coordinates[1] + lon_degrees, bbox_coordinates[3] + lat_degrees\n",
        "\n",
        "    # Calculate new bounding box coordinates\n",
        "    y_max = y_min + lon_degrees / 2\n",
        "    x_max = x_min + lat_degrees\n",
        "\n",
        "    # Generate shapely polygons for the bounding boxes\n",
        "    scalebar_list = []\n",
        "    for i in range(3):\n",
        "        x_min_i = x_min + (lat_degrees ) * i\n",
        "        x_max_i = x_min + (lat_degrees) * (i + 1)\n",
        "        scalebar_list.append(box(x_min_i, y_min, x_max_i, y_max))\n",
        "\n",
        "    # Update bounding box coordinates\n",
        "    bbox_coords_updated = [y_max, y_min, x_max, x_min]\n",
        "\n",
        "    return scalebar_list, bbox_coords_updated\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## create polygon radius"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "iyZFxkrfTbM5"
      },
      "outputs": [],
      "source": [
        "#@title def create polygon radius\n",
        "import shapely\n",
        "from shapely import Point\n",
        "\n",
        "def create_radius_from_bbox(center_point, bounding_box, dist_plot):\n",
        "\n",
        "    lat_degrees, lon_degrees = meters_to_degrees(center_point, dist_plot)\n",
        "\n",
        "    #create ellipse from circle from point\n",
        "    center_point_point = Point(center_point[1], center_point[0])\n",
        "    circle = center_point_point.buffer(lon_degrees)\n",
        "    ellipse = shapely.affinity.scale(circle, lat_degrees/lon_degrees, 1)\n",
        "\n",
        "    #subtract the ellipse from the bbox\n",
        "    difference = bounding_box.difference(ellipse)\n",
        "\n",
        "    return difference\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## def plotting points roads, vegetation, water"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59tNW48MrlIA"
      },
      "outputs": [],
      "source": [
        "#@title def plotting points roads, vegetation, water\n",
        "import osmnx as ox\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_from_multiple_points(index, G, edges_gdf02_exploded, buildings_osm, park_natural,\n",
        "                              landuse_natural, water_natural, wetland_natural, tree_natural,\n",
        "                              center_point, scalebar_polygons, multipolygon_radius, text\n",
        "                              fig_size=[10,10], dpi=600, bbox=None):\n",
        "    \"\"\"\n",
        "    Plot the road network, buildings, and natural features from multiple data sets.\n",
        "\n",
        "    Parameters:\n",
        "        - G: Graph representing the road network.\n",
        "        - edges_gdf02_exploded: GeoDataFrame representing exploded edges.\n",
        "        - buildings_osm: GeoDataFrame representing buildings.\n",
        "        - park_natural: GeoDataFrame representing parks.\n",
        "        - landuse_natural: GeoDataFrame representing land use.\n",
        "        - water_natural: GeoDataFrame representing water bodies.\n",
        "        - tree_natural: GeoDataFrame representing trees.\n",
        "        - center_point: Tuple representing the center point for scatter plot.\n",
        "        - fig_size: Size of the figure (default=[15,15]).\n",
        "        - dpi: Dots per inch for the figure resolution (default=600).\n",
        "    \"\"\"\n",
        "    # Plot the road network and exploded edges if G is not None\n",
        "    if G is not None:\n",
        "        fig, ax = ox.plot_graph(G, figsize=fig_size, bgcolor='lightgrey', node_color='red', node_size=10,\n",
        "                                node_alpha=0, node_edgecolor='none', node_zorder=1, edge_color='xkcd:pastel red',\n",
        "                                edge_linewidth=2, edge_alpha=0.3, show=False, close=False, save=False,\n",
        "                                filepath=None, dpi=dpi, bbox=bbox)\n",
        "\n",
        "    # edges_gdf02_exploded.plot(ax=ax, color='white', linewidth=edges_gdf02_exploded['road_width']*4, alpha=0.2, legend=True)\n",
        "    edges_gdf02_exploded.plot(ax=ax, color=edges_gdf02_exploded['edge_color_roadtype'],\n",
        "                              linewidth=edges_gdf02_exploded['road_width']*8, alpha=0.5, legend=True)\n",
        "\n",
        "    # Plot buildings on the same axis if buildings_osm is not None\n",
        "    if buildings_osm is not None:\n",
        "        fig, ax = ox.plot_footprints(buildings_osm, ax=ax, figsize=fig_size, color='white', edge_color='black',\n",
        "                                     edge_linewidth=1, alpha=0.8,\n",
        "                                     bgcolor='grey', bbox=bbox, save=False, show=False, close=False, filepath=None, dpi=dpi)\n",
        "\n",
        "    # Scatter plot for center point\n",
        "    plt.scatter(center_point[1], center_point[0], color='red', label='Center Point', zorder=3)\n",
        "\n",
        "    for geom in scalebar_polygons:\n",
        "      xs, ys = geom.exterior.xy\n",
        "      ax.fill(xs, ys, alpha=1, fc='black', ec='white', zorder= 4)\n",
        "\n",
        "    radius = gpd.GeoSeries(multipolygon_radius)\n",
        "    radius.plot(ax=ax, color = 'white', zorder=3 )\n",
        "    plt.text(bbox[0], bbox[2], text)\n",
        "\n",
        "    # Define data sets for natural features\n",
        "    data_sets = [\n",
        "        (park_natural, 'darkseagreen', 50, 'park_natural', 0.5, 2),\n",
        "        (vegetation_natural, 'purple', 0.5, 'vegetation',0.1, 1), #natural all\n",
        "        (landuse_natural, 'yellowgreen', 50, 'landuse_natural', 0.5, 1), #grass\n",
        "        (water_natural, 'teal', 1, 'water_natural', 0.5, 1),\n",
        "        (wetland_natural, 'teal', 1, 'tan', 0.1, 1),\n",
        "        (tree_natural, 'olivedrab', 150, 'tree_natural', 0.7, 2),\n",
        "        (tree_natural, 'darkolivegreen', 2.5, 'tree_natural', 0.5, 2) #double to create a 'stem'\n",
        "    ]\n",
        "\n",
        "    # Plot each data set\n",
        "    for data, color, size, label, alpha, zorder in data_sets:\n",
        "        if data is not None:\n",
        "            data.plot(ax=ax, markersize=size, color=color, label=label, alpha=alpha, zorder=zorder)\n",
        "\n",
        "    # temp_file_path = f'240226_point_{index}_plot.png'\n",
        "    # plt.savefig(temp_file_path)\n",
        "    # files.download(temp_file_path) # # Download the temporary file to the local computer\n",
        "\n",
        "    ## GOOGLE COLAB\n",
        "    # Define the file path within the folder\n",
        "    # temp_file_path = os.path.join(folder_path, f'240226_sample_point_{index}_plot.png')\n",
        "    # Save the plot directly to the specified folder\n",
        "    # plt.savefig(temp_file_path)\n",
        "    \n",
        "    ## VSCODE\n",
        "    # Construct the filename string\n",
        "    filename = f\"240228_plot_{index}.png\"\n",
        "    # Save the plot to the specified folder with the constructed filename\n",
        "    plt.savefig(r'C:/Users/n.smit/OneDrive - Oosterhoff Group/Documents/Master Thesis/DATA/plot_maps/' + filename)\n",
        "\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.show()\n",
        "    plt.close(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## def to load data for each point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "oMgd7T6_kLFi"
      },
      "outputs": [],
      "source": [
        "#@title def to load data for each point\n",
        "def load_data_for_point(row, distance=100):\n",
        "\n",
        "    point = (row['latitude'], row['longitude'])\n",
        "    size = distance + 50\n",
        "    distance = distance + 50\n",
        "\n",
        "    # Fetch street network\n",
        "    G = ox.graph_from_point(point, dist=distance, network_type='all')\n",
        "    # edges_gdf = ox.graph_to_gdfs(G, nodes=False, edges=True)\n",
        "    # new_network = ox.graph_from_gdfs(nodes_gdf, edges_gdf)\n",
        "\n",
        "    # Preprocess street network data\n",
        "    # edges_gdf = preprocess_street_network(G)\n",
        "\n",
        "    # Load natural features\n",
        "    vegetation_natural = load_osm_data(point, tags_natural, size=size)  #Natural : True\n",
        "    landuse_natural_grass = load_osm_data(point, tags_landuse, size=size)\n",
        "    park_natural = load_osm_data(point, tags_parks, size=size)\n",
        "    water_natural = load_osm_data(point, tags_water, size=size)\n",
        "    wetland_natural = load_osm_data(point, tags_wetland, size=size)\n",
        "    tree_natural = load_osm_data(point, tags_tree, size=size-40)\n",
        "\n",
        "    # Load buildings\n",
        "    buildings_osm = load_osm_data(point, tags_buildings, size=size)\n",
        "\n",
        "    return G, vegetation_natural, landuse_natural_grass, park_natural, water_natural, wetland_natural,  tree_natural, buildings_osm\n",
        "\n",
        "# Function to preprocess street network data\n",
        "def preprocess_street_network(G):\n",
        "    edges_gdf = ox.graph_to_gdfs(G, nodes=False, edges=True)\n",
        "    edges_gdf_exploded = edges_gdf.explode('highway')\n",
        "    edges_gdf_exploded['road_width'] = edges_gdf_exploded['highway'].map(road_width).fillna(3)\n",
        "    edges_gdf_exploded['edge_color_roadtype'] = edges_gdf_exploded['highway'].map(road_type_colors).fillna('purple')\n",
        "    return edges_gdf_exploded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## function for loading the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhTd3jcknkSU",
        "outputId": "f25aa2ac-2071-4365-9878-42d5c5fa90c5"
      },
      "outputs": [],
      "source": [
        "#@title function for loading the images\n",
        "# from google.colab import files\n",
        "\n",
        "distance = 70\n",
        "meters = 1\n",
        "# Calculate how many degrees correspond to 1 meters\n",
        "\n",
        "\n",
        "# Now, unique values can be extracted without any lists\n",
        "unique_values_lists = []\n",
        "print(unique_values_lists)\n",
        "\n",
        "\n",
        "# Loop through each point\n",
        "for index, row in ssid_gdf_1_per_location.iterrows():\n",
        "    print('Processing data for Point', index, 'in',  row['LocationID'])\n",
        "    center_point = (row['latitude'], row['longitude'])\n",
        "    lat_degrees, lon_degrees = meters_to_degrees(center_point, meters)\n",
        "\n",
        "    bounding_box, bbox_coordinates = get_bounding_box(center_point, distance)\n",
        "    scalebar_polygons, scale_coordinates  = create_scale_bar(bbox_coordinates, center_point, meters = 4)\n",
        "    multipolygon_radius = create_radius_from_bbox(center_point, bounding_box, distance)\n",
        "\n",
        "    # Load data for the current point\n",
        "    network, vegetation_natural, landuse_natural, park_natural, water_natural, wetland_natural, tree_natural, buildings_osm = load_data_for_point(row, distance)\n",
        "    edges_gdf = preprocess_street_network(network)\n",
        "\n",
        "    # park_natural = create_inner_polygons(park_natural, lat_degrees*5)\n",
        "    unique_values_list = edges_gdf['highway'].unique().tolist()\n",
        "    unique_values_lists.append(unique_values_list)\n",
        "    print(unique_values_lists)\n",
        "    # Plotting\n",
        "    plot_from_multiple_points(index, network, edges_gdf, buildings_osm, park_natural, landuse_natural,\n",
        "                              water_natural, wetland_natural, tree_natural, center_point,\n",
        "                              scalebar_polygons, multipolygon_radius,\n",
        "                              fig_size=[10,10], dpi=600, bbox=bbox_coordinates)\n",
        "\n",
        "    # # Save the plot as an image\n",
        "    # plt.savefig(f'point_{index}_plot.png')\n",
        "    # plt.close(fig)\n",
        "    # Save the plot to a temporary file\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5lQaSuTU6QO",
        "outputId": "5ad24a6c-7015-468d-cace-c5d8f3aa3a2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error loading {'natural': ['fell', 'grassland', 'health', 'scrub', 'wood']} data: [Errno 107] Transport endpoint is not connected: 'cache/91edd4dbc07d1dc706f6231228d6cb67793a872c.json'\n"
          ]
        }
      ],
      "source": [
        "# Define tags for natural features excluding trees\n",
        "tags_natural_exclude_trees = {'natural': ['fell', 'grassland', 'health', 'scrub', 'wood' ]}\n",
        "\n",
        "vegetation_natural = load_osm_data(center_point, tags_natural_exclude_trees, size=300)\n",
        "# Load OSMnx data with natural features excluding trees\n",
        "# gdf_filtered_natural = ox.geometries_from_place(place_name, tags=tags_natural_exclude_trees)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fomg8-sGVuGg",
        "outputId": "eafd4f6f-7ccb-4706-c4ea-0155d67cea48"
      },
      "outputs": [],
      "source": [
        "import geopandas as gpd\n",
        "\n",
        "# Assuming vegetation_natural is your GeoDataFrame\n",
        "\n",
        "# Calculate the area of each geometry (assuming they are polygons)\n",
        "vegetation_natural['area'] = vegetation_natural.geometry.area\n",
        "\n",
        "# Sort the GeoDataFrame based on the area\n",
        "vegetation_natural_sorted = vegetation_natural.sort_values(by='area', ascending=False)\n",
        "\n",
        "# Remove the area column if you don't need it anymore\n",
        "vegetation_natural_sorted.drop(columns=['area'], inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqujxDmFVfJU"
      },
      "outputs": [],
      "source": [
        "vegetation_natural"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-CH8QYpOClU"
      },
      "source": [
        "#Load OSM roads\n",
        " graphs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMnpm0kYi-T4"
      },
      "source": [
        "## roads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVBDa2KiMgxF",
        "outputId": "4d564c42-dd86-4dee-e258-afdb862d481d"
      },
      "outputs": [],
      "source": [
        "# Convert the GeoDataFrame to a list of points\n",
        "points_lon_lat = list(zip(ssid_gdf['latitude'], ssid_gdf['longitude']))\n",
        "\n",
        "# Get the center point of the GeoDataFrame\n",
        "center_point = points_lon_lat[0]  # Considering the first row as the center point\n",
        "distance = 300  # in meters\n",
        "# Fetch the street network\n",
        "G = ox.graph_from_point(center_point, dist=distance, network_type='all')\n",
        "print(center_point)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2AcUTy8ixQG"
      },
      "source": [
        "###colors for the roads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cp73CRU7dFK0",
        "outputId": "84b5c4ec-8590-4c8c-8e31-9b5e74c63625"
      },
      "outputs": [],
      "source": [
        "G = ox.distance.add_edge_lengths(G, edges=None)\n",
        "G = ox.add_edge_speeds(G, hwy_speeds)\n",
        "basic_stats_G = ox.stats.basic_stats(G, area=None, clean_int_tol=None)\n",
        "basic_stats_G"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBkbJVeUtkUs"
      },
      "source": [
        "## edge colors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDoVwunF0ACQ"
      },
      "source": [
        "create a gdf from the road network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKMrE-eEjEpn",
        "outputId": "d5419210-069d-4b05-8101-cb6e9deeba09"
      },
      "outputs": [],
      "source": [
        "#create gdfs for the nodes and edges. Create a newwork from that. Create new gdfs from this one\n",
        "nodes_gdf00, edges_gdf00 = ox.graph_to_gdfs(G, nodes=True, edges=True)\n",
        "new_network = ox.graph_from_gdfs(nodes_gdf00, edges_gdf00)\n",
        "\n",
        "# Create the geodataframes nodes_gdf and edges_gdf\n",
        "nodes_gdf02, edges_gdf02 = ox.graph_to_gdfs(new_network, nodes=True, edges=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "srE38CJH1y4r",
        "outputId": "a674936e-dd31-408c-e432-41816f33e156"
      },
      "outputs": [],
      "source": [
        "edges_gdf00.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "wC7J-q0iwF1f",
        "outputId": "0a0848cb-82a0-4c51-cb9e-77d66a683313"
      },
      "outputs": [],
      "source": [
        "#explode the column to get all the values\n",
        "edges_gdf02_exploded = edges_gdf02.explode('highway')\n",
        "\n",
        "# Now, unique values can be extracted without any lists\n",
        "unique_values_list = edges_gdf02_exploded['highway'].unique().tolist()\n",
        "print(unique_values_list)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ga8h9ZXl8h5J"
      },
      "source": [
        "## add colors and width\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8zvJOFpPito",
        "outputId": "72e35336-1c60-49b8-eda2-de619b15cd7b"
      },
      "outputs": [],
      "source": [
        "# Create a new column for edge width based on road type\n",
        "edges_gdf02_exploded['road_width'] = edges_gdf02_exploded['highway'].map(road_width).fillna(1)\n",
        "# Create a new column for edge colors based on road type\n",
        "edges_gdf02_exploded['edge_color_roadtype'] = edges_gdf02_exploded['highway'].map(road_type_colors).fillna('purple')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0A6mIk_zPito",
        "outputId": "3634a73e-fdc8-4290-e845-20c20956b4f1"
      },
      "outputs": [],
      "source": [
        "# Plotting the road network with the corresponding edge colors and edge widths\n",
        "fig_size = [10,10]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=fig_size)\n",
        "edges_gdf02_exploded.plot(ax=ax,  color=edges_gdf02_exploded['edge_color_roadtype'],linewidth=edges_gdf02_exploded['road_width']*2, alpha = 0.5, legend=True)\n",
        "\n",
        "# Add a legend for the edge colors\n",
        "legend_elements = [plt.Line2D([0], [0], marker='o', color='w', label=road_type, markerfacecolor=color)\n",
        "                   for road_type, color in road_type_colors.items()]\n",
        "plt.legend(handles=legend_elements, title='Road Types')\n",
        "ax.set_title('Road Types ')\n",
        "\n",
        "# Display the plot\n",
        "plt.axis('on')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d23vTVQ-XKAM"
      },
      "source": [
        "## folium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "9M2Ha6ceQ_7A",
        "outputId": "7a528ceb-757f-4ce2-c6d4-1efffdcbd1fd"
      },
      "outputs": [],
      "source": [
        "import folium\n",
        "\n",
        "# Create a map centered at the defined point\n",
        "mymap = folium.Map(location=center_point, zoom_start=15)\n",
        "\n",
        "# Example: Add a marker at the center point\n",
        "folium.Marker(center_point, popup='Center Point').add_to(mymap)\n",
        "\n",
        "for i in points_lon_lat:\n",
        "  folium.Marker(i, popup='Center Point').add_to(mymap)\n",
        "\n",
        "folium.LayerControl().add_to(mymap)\n",
        "# Display the map\n",
        "mymap.save('mymap.html')  # Save the map to an HTML file\n",
        "# mymap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJnEy1jnPWWY"
      },
      "source": [
        "# Load OSM vegetation + buildings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlvQaCUBpzvb",
        "outputId": "cb1d6521-1659-4a88-bc87-80bc7c8465ed"
      },
      "outputs": [],
      "source": [
        "#load vegetation\n",
        "vegetation_natural = load_osm_data(center_point, tags_natural, size = 300 )\n",
        "landuse_natural = load_osm_data(center_point, tags_landuse, size = 300 )\n",
        "park_natural = load_osm_data(center_point, tags_parks, size = 300 )\n",
        "water_natural = load_osm_data(center_point, tags_water, size = 300)\n",
        "tree_natural = load_osm_data(center_point, tags_tree, size = 300 )\n",
        "\n",
        "#load buildings\n",
        "buildings_osm = load_osm_data(center_point, tags_buildings, size = 400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOv7eRT6OdP_",
        "outputId": "538e5c5b-df85-4b89-b3d7-dc33077e41bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "At latitude 51.539124, 1 meters correspond to approximately 1.4442830144070832e-05 degrees of latitude and 8.983152841195214e-06 degrees of longitude.\n"
          ]
        }
      ],
      "source": [
        "longitude = center_point[1]\n",
        "latitude = center_point[0]\n",
        "# meters = distance\n",
        "meters = 1\n",
        "# Calculate how many degrees correspond to 50 meters\n",
        "lat_degrees, lon_degrees = meters_to_degrees(center_point, meters)\n",
        "\n",
        "print(\"At latitude {}, {} meters correspond to approximately {} degrees of latitude and {} degrees of longitude.\".format(latitude, meters, lat_degrees, lon_degrees))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKzsGD0DFHvg"
      },
      "outputs": [],
      "source": [
        "dist_plot = 300\n",
        "\n",
        "bounding_box, bbox_coordinates = get_bounding_box(center_point, dist_plot)\n",
        "scalebar_polygons, scale_coordinates  = create_scale_bar(bbox_coordinates, center_point, meters = 4)\n",
        "multipolygon_radius = create_radius_from_bbox(center_point, bounding_box, dist_plot)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooYab4O70jC3",
        "outputId": "11223334-a59f-4fa9-c38a-0cc3060da0d3"
      },
      "outputs": [],
      "source": [
        "gdf_trunk = edges_gdf02_exploded[edges_gdf02_exploded['highway']== 'trunk']\n",
        "gdf_primary = edges_gdf02_exploded[edges_gdf02_exploded['highway']== 'primary']\n",
        "\n",
        "buffer_trunk = gdf_trunk.buffer(lat_degrees/10)\n",
        "\n",
        "gdf_trunk.plot()\n",
        "# gdf_primary.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Gx7LEPy6Jfm"
      },
      "source": [
        "#plot all together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49Y9zeCD6JK_",
        "outputId": "7a6f32e5-1f38-47d9-ebec-38cc3fb364f0"
      },
      "outputs": [],
      "source": [
        "fig_size= [10,10]\n",
        "dpi=600\n",
        "if G is not None:\n",
        "# Plot the road network\n",
        "    fig, ax = ox.plot_graph(G, figsize=fig_size, bgcolor='lightgrey', node_color='red', node_size=10,\n",
        "                        node_alpha=0, node_edgecolor='none', node_zorder=1, edge_color='xkcd:pastel red',\n",
        "                        edge_linewidth=1, edge_alpha=0.2, show=False, close=False, save=False, filepath=None,\n",
        "                            dpi=dpi, bbox=bbox_coordinates)\n",
        "\n",
        "edges_gdf02_exploded.plot(ax=ax, color='white',linewidth=edges_gdf02_exploded['road_width']*4, alpha = 0.2, legend=True)\n",
        "\n",
        "edges_gdf02_exploded.plot(ax=ax, color=edges_gdf02_exploded['edge_color_roadtype'],linewidth=edges_gdf02_exploded['road_width']*4,\n",
        "                          alpha = 0.6, legend=True)\n",
        "\n",
        "if buildings_osm is not None:\n",
        "    # Plot buildings on the same axis\n",
        "    fig, ax = ox.plot_footprints(buildings_osm, ax=ax, figsize=fig_size, color='white', edge_color='black', edge_linewidth=1, alpha=0.7,\n",
        "                                bgcolor='grey', bbox=bbox_coordinates, save=False, show=False, close=False, filepath=None, dpi=dpi)\n",
        "\n",
        "# ssid_gdf.plot(ax=ax, cmap='cool', alpha=0.7, markersize=50, legend=True)\n",
        "plt.scatter(center_point[1], center_point[0], color='red', label='Center Point', zorder =2)\n",
        "\n",
        "\n",
        "for geom in scalebar_polygons:\n",
        "  xs, ys = geom.exterior.xy\n",
        "  ax.fill(xs, ys, alpha=1, fc='black', ec='white', zorder= 4)\n",
        "\n",
        "radius = gpd.GeoSeries(multipolygon_radius)\n",
        "radius.plot(ax=ax, color = 'white', zorder=3 )\n",
        "# for geom in difference:\n",
        "#   x,y = geom.exterior.xy\n",
        "#   plt.plot(x,y)\n",
        "# p = gpd.GeoSeries(poly)\n",
        "# p.plot(ax=ax, color = 'purple', alpha = 1)\n",
        "#  plt.show()\n",
        "# poly.plot(ax=ax, color = 'purple', alpha = 0.2, edge_color = 'blue')\n",
        "data_sets = [\n",
        "    (park_natural, 'darkseagreen', 50, 'park_natural', 0.1),\n",
        "    #(vegetation_natural, 'forestgreen', 50, 'vegetation', 1),\n",
        "    (landuse_natural, 'yellowgreen', 50, 'landuse_natural', 0.1),\n",
        "    (water_natural, 'seagreen', 1, 'water_natural', 0.5),\n",
        "    (tree_natural, 'olivedrab', 100, 'tree_natural', 0.5),\n",
        "    (tree_natural, 'darkolivegreen', 1, 'tree_natural', 0.5) #double to create a 'stem'\n",
        "]\n",
        "\n",
        "for data, color, size, label, alpha in data_sets:\n",
        "    if data is not None:\n",
        "        data.plot(ax=ax, markersize=size, color=color, label=label, alpha=alpha, zorder = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBFqRP6qOxvG",
        "outputId": "da655d10-b678-4ffc-9b26-a94c49bfa6a4"
      },
      "outputs": [],
      "source": [
        "filter_location = ['MonumentoGaribaldi']\n",
        "ssid_gdf_locationxx = ssid_gdf.loc[ssid['LocationID'].isin(filter_location)]\n",
        "points_lon_latxx = list(zip(ssid_gdf_locationxx['latitude'], ssid_gdf_locationxx['longitude']))\n",
        "\n",
        "# Get the center point of the GeoDataFrame\n",
        "center_point = points_lon_latxx[0]\n",
        "park_natural = load_osm_data(center_point, tags_parks, size = 300 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UNL5o_jpBVvN",
        "outputId": "6d3807fa-dc29-4c4c-ed4d-b1dfe3faf0ad"
      },
      "outputs": [],
      "source": [
        "def create_inner_polygon(row, buffer_distance):\n",
        "    # print(row)\n",
        "    outer_polygon = row\n",
        "    inner_polygons = []\n",
        "\n",
        "    # Check if the geometry is a MultiPolygon\n",
        "    if outer_polygon.geom_type == 'MultiPolygon':\n",
        "        print(outer_polygon)\n",
        "        polygons = list(outer_polygon.geoms)\n",
        "        # Iterate over each polygon in the MultiPolygon\n",
        "        for polygon in polygons:\n",
        "            print(polygon)\n",
        "            inner_polygon = polygon.buffer(-buffer_distance)\n",
        "            # Append the inner polygon to the list\n",
        "            inner_polygons.append(inner_polygon)\n",
        "    else:\n",
        "        # For single polygons, directly buffer inward\n",
        "        inner_polygon = outer_polygon.buffer(-buffer_distance)\n",
        "        inner_polygons.append(inner_polygon)\n",
        "\n",
        "    # Find the largest inner polygon (by area) if there are multiple\n",
        "    if inner_polygons:\n",
        "        largest_inner_polygon = max(inner_polygons, key=lambda polygon: polygon.area)\n",
        "        return largest_inner_polygon\n",
        "    else:\n",
        "        # Return None if there are no inner polygons\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_inner_polygons(park_natural, buffer_distance):\n",
        "    \"\"\"\n",
        "    Function to create inner polygons for each polygon in a GeoDataFrame.\n",
        "\n",
        "    Args:\n",
        "    park_natural (GeoDataFrame): GeoDataFrame containing polygon geometries.\n",
        "    buffer_distance (float): Distance to buffer the polygons inward to create inner polygons.\n",
        "\n",
        "    Returns:\n",
        "    GeoDataFrame: GeoDataFrame containing both the original polygons and the inner polygons.\n",
        "    \"\"\"\n",
        "    # # Function to create inner polygon for each row in the GeoDataFrame\n",
        "    # def create_inner_polygon(row, buffer_distance):\n",
        "    #     outer_polygon = row\n",
        "    #     inner_polygon = outer_polygon.buffer(-buffer_distance)  # Buffer with a negative distance to create inner polygon\n",
        "    #     if inner_polygon.geom_type == 'MultiPolygon':\n",
        "    #         inner_polygon = max(inner_polygon, key=lambda polygon: polygon.area)\n",
        "    #     return inner_polygon\n",
        "\n",
        "    # Create inner polygons\n",
        "    # print(park_natural.geom_type)\n",
        "    print(park_natural)\n",
        "    if park_natural is not None:\n",
        "        inner_polygons = gpd.GeoDataFrame(geometry=park_natural.geometry.apply(create_inner_polygon, args=(buffer_distance,)), crs=park_natural.crs)\n",
        "        inner_polygons01 = gpd.GeoDataFrame(geometry=inner_polygons.geometry.apply(create_inner_polygon, args=(buffer_distance,)), crs=park_natural.crs)\n",
        "\n",
        "        # Concatenate inner_polygons and inner_polygons01\n",
        "        combined_inner_polygons = pd.concat([inner_polygons, inner_polygons01])\n",
        "\n",
        "        # Add a column to identify the type of inner polygon (if needed)\n",
        "        combined_inner_polygons['inner_polygon_type'] = ['inner_polygons']*len(inner_polygons) + ['inner_polygons01']*len(inner_polygons01)\n",
        "\n",
        "        # Append combined inner polygons to the original GeoDataFrame\n",
        "        park_natural_with_inner = pd.concat([park_natural, combined_inner_polygons]).reset_index(drop=True)\n",
        "\n",
        "    else:\n",
        "        park_natural_with_inner = park_natural\n",
        "\n",
        "    return park_natural_with_inner\n",
        "\n",
        "# Example usage:\n",
        "# park_natural_gdf is your GeoDataFrame containing the polygons\n",
        "# buffer_distance is the distance to buffer inward to create inner polygons\n",
        "park_natural_with_inner = create_inner_polygons(park_natural, lat_degrees*2)\n",
        "# Plotting for visualization\n",
        "fig, ax = plt.subplots()\n",
        "park_natural_with_inner.plot(ax=ax, color='lightgreen', edgecolor= None, alpha=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndcXKVt2yIOi"
      },
      "source": [
        "# load data per location"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## def to load data for each point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Dbw2_K0hyTgq"
      },
      "outputs": [],
      "source": [
        "#@title def to load data for each point\n",
        "def load_data_for_center_point(point, distance=50):\n",
        "\n",
        "    # point = (row['latitude'], row['longitude'])\n",
        "    size = distance + 50\n",
        "    distance = distance + 50\n",
        "\n",
        "    # Fetch street network\n",
        "    G = ox.graph_from_point(point, dist=distance, network_type='all')\n",
        "    # edges_gdf = ox.graph_to_gdfs(G, nodes=False, edges=True)\n",
        "    # new_network = ox.graph_from_gdfs(nodes_gdf, edges_gdf)\n",
        "\n",
        "    # Preprocess street network data\n",
        "    # edges_gdf = preprocess_street_network(G)\n",
        "\n",
        "    # Load natural features\n",
        "    vegetation_natural = load_osm_data(point, tags_natural, size=size)  #Natural : True\n",
        "    landuse_natural_grass = load_osm_data(point, tags_landuse, size=size)\n",
        "    park_natural = load_osm_data(point, tags_parks, size=size)\n",
        "    water_natural = load_osm_data(point, tags_water, size=size)\n",
        "    wetland_natural = load_osm_data(point, tags_wetland, size=size)\n",
        "    tree_natural = load_osm_data(point, tags_tree, size=size-40)\n",
        "\n",
        "    # Load buildings\n",
        "    buildings_osm = load_osm_data(point, tags_buildings, size=size)\n",
        "\n",
        "    return G, vegetation_natural, landuse_natural_grass, park_natural, water_natural, wetland_natural,  tree_natural, buildings_osm\n",
        "\n",
        "# Function to preprocess street network data\n",
        "def preprocess_street_network(G):\n",
        "    edges_gdf = ox.graph_to_gdfs(G, nodes=False, edges=True)\n",
        "    edges_gdf_exploded = edges_gdf.explode('highway')\n",
        "    edges_gdf_exploded['road_width'] = edges_gdf_exploded['highway'].map(road_width).fillna(3)\n",
        "    edges_gdf_exploded['edge_color_roadtype'] = edges_gdf_exploded['highway'].map(road_type_colors).fillna('purple')\n",
        "    return edges_gdf_exploded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "C_yoWCl_yKD3",
        "outputId": "caa12a8b-b208-48ef-8068-b7a745f861d2"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import zscore\n",
        "import numpy as np\n",
        "\n",
        "def replace_outliers_w_zero(gdf, threshold=1, null_object=np.nan):\n",
        "    \"\"\"\n",
        "    Replace outliers in a GeoDataFrame with a null object based on z-scores of latitude and longitude.\n",
        "\n",
        "    Parameters:\n",
        "    - gdf: GeoDataFrame with 'latitude' and 'longitude' columns.\n",
        "    - threshold: Z-score threshold for identifying outliers (default is 3).\n",
        "    - null_object: Value to replace outliers with (default is np.nan).\n",
        "\n",
        "    Returns:\n",
        "    - gdf_no_outliers: GeoDataFrame with outliers replaced by null_object.\n",
        "    - outliers: DataFrame containing the identified outliers.\n",
        "    - outliers_count: Number of outliers replaced.\n",
        "    \"\"\"\n",
        "    latitudes = gdf['latitude']\n",
        "    longitudes = gdf['longitude']\n",
        "\n",
        "    # Calculate z-scores for latitudes and longitudes\n",
        "    z_scores_lat = zscore(latitudes)\n",
        "    z_scores_lon = zscore(longitudes)\n",
        "\n",
        "    # Identify outliers based on either latitude or longitude\n",
        "    outliers_mask = (abs(z_scores_lat) > threshold) | (abs(z_scores_lon) > threshold)\n",
        "\n",
        "    # Create a copy of the GeoDataFrame to avoid modifying the original data\n",
        "    gdf_no_outliers = gdf.copy()\n",
        "\n",
        "    # Replace outliers with null_object\n",
        "    # gdf_no_outliers.loc[outliers_mask, ['latitude', 'longitude']] = 0\n",
        "\n",
        "    gdf_no_outliers['outlier'] = outliers_mask\n",
        "\n",
        "    # Create a DataFrame containing the identified outliers\n",
        "    outliers = gdf_no_outliers[outliers_mask]\n",
        "    gdf_remove_outliers = gdf_no_outliers[~outliers_mask]\n",
        "\n",
        "    # Count of outliers replaced\n",
        "    outliers_count = outliers_mask.sum()\n",
        "\n",
        "    return gdf_no_outliers, outliers, outliers_count\n",
        "\n",
        "def calculate_center_point(gdf):\n",
        "    \"\"\"\n",
        "    Calculate the center point based on the median latitude and longitude of a GeoDataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - gdf: GeoDataFrame with 'latitude' and 'longitude' columns.\n",
        "\n",
        "    Returns:\n",
        "    - center_point: Tuple containing the latitude and longitude of the center point.\n",
        "    \"\"\"\n",
        "\n",
        "    # Remove outliers from the original GeoDataFrame\n",
        "    gdf = gdf[gdf['outlier'] != True]\n",
        "    latitudes = gdf['latitude']\n",
        "    longitudes = gdf['longitude']\n",
        "\n",
        "\n",
        "    # Calculate the median of latitudes and longitudes\n",
        "    latitude_median = latitudes.median()\n",
        "    longitude_median = longitudes.median()\n",
        "\n",
        "    # Create a center point tuple\n",
        "    center_point = (latitude_median, longitude_median)\n",
        "    center_point_point = gdf.dissolve().centroid\n",
        "\n",
        "    return center_point, center_point_point\n",
        "\n",
        "def is_nearby(point, central_point, distance=lat_degrees*100):\n",
        "    value = point.distance(central_point) <= distance\n",
        "    # print(value)\n",
        "    return value\n",
        "\n",
        "outliers_counts = []\n",
        "groups = []\n",
        "groups_no_outliers = []\n",
        "\n",
        "for location_id, group in ssid_gdf.groupby('LocationID'):\n",
        "    print('calculating for', location_id)\n",
        "    group_no_outliers, outliers, outliers_count = replace_outliers_w_zero(group)\n",
        "\n",
        "\n",
        "    center_point, center_point_point = calculate_center_point(group_no_outliers)\n",
        "    # print(center_point)\n",
        "    group['nearby'] = group.apply(lambda row: is_nearby(row['geometry'],\n",
        "                                                                    center_point_point), axis=1)\n",
        "\n",
        "    for index, row in g.iterrows():\n",
        "    G, vegetation_natural, landuse_natural, park_natural, water_natural, wetland_natural, tree_natural, buildings_osm = load_data_for_center_point(center_point)\n",
        "\n",
        "    edges_gdf = preprocess_street_network(G)\n",
        "\n",
        "    # lat_degrees, lon_degrees = meters_to_degrees(center_point, meters)\n",
        "    bounding_box, bbox_coordinates = get_bounding_box(center_point, distance)\n",
        "    scalebar_polygons, scale_coordinates  = create_scale_bar(bbox_coordinates, center_point, meters = 4)\n",
        "    multipolygon_radius = create_radius_from_bbox(center_point, bounding_box, distance)\n",
        "\n",
        "    # Plotting\n",
        "    plot_from_multiple_points(index, G, edges_gdf, buildings_osm, park_natural, landuse_natural,\n",
        "                              water_natural, wetland_natural, tree_natural, center_point,\n",
        "                              scalebar_polygons, multipolygon_radius,\n",
        "                              fig_size=[10,10], dpi=600, bbox=bbox_coordinates)\n",
        "    outliers_counts.append(outliers_count)\n",
        "    groups.append(group)\n",
        "    groups_no_outliers.append(group_no_outliers)\n",
        "\n",
        "\n",
        "# Print the number of outliers removed\n",
        "print(f\"\\nNumber of outliers replaced: {outliers_counts}\")\n",
        "\n",
        "# # Print the outliers\n",
        "# print(\"Outliers:\")\n",
        "# print(outliers)\n",
        "group_no_outliers = groups_no_outliers[0]\n",
        "group_no_outliers[group_no_outliers['outlier'] == True]\n",
        "group01 = groups[7]\n",
        "group01[group01['nearby'] == False]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GldTKMyEbx8"
      },
      "source": [
        "# svm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1obys7QE2Qz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "# Directory containing the images\n",
        "directory = '/content/drive/MyDrive/Colab Notebooks/240226_allpoints/sample_1/'\n",
        "# List all image files in the directory\n",
        "image_files = [file for file in os.listdir(directory) if file.endswith(('jpg', 'png', 'jpeg'))]\n",
        "\n",
        "# Load images\n",
        "images = []\n",
        "for filename in image_files:\n",
        "    image_path = os.path.join(directory, filename)\n",
        "    image = Image.open(image_path)\n",
        "    images.append(image)\n",
        "\n",
        "print(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnIvA6SIFL7b"
      },
      "outputs": [],
      "source": [
        "ssid_gdf_3_per_location"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSVnMWZREdTc"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Preprocess and extract features from your image and geospatial data\n",
        "# Assuming you have extracted features and stored them in X_image and X_geospatial, and labels in y\n",
        "\n",
        "# Convert images list to a numpy array\n",
        "X_image = np.array(images)\n",
        "\n",
        "# Assuming 'X_geospatial' is already a 1-dimensional numpy array\n",
        "X_geospatial = ssid_gdf_3_per_location['ISOPleasant'].values\n",
        "# Assuming X_image is a numpy array and X_geospatial is a list\n",
        "X_geospatial_array = np.array(X_geospatial)\n",
        "\n",
        "# Concatenate image and geospatial features\n",
        "X_combined = np.concatenate((X_image, X_geospatial_array.reshape(-1, 1)), axis=1)\n",
        "# X_geospatial = ssid_gdf_3_per_location['ISOPleasant'].reset_index(drop=True)\n",
        "# Concatenate image and geospatial features\n",
        "# X_combined = np.concatenate((X_image, X_geospatial.reshape(-1, 1)), axis=1)\n",
        "# 2. Concatenate image and geospatial features\n",
        "# X_combined = np.concatenate((X_image, X_geospatial), axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 3. Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4. Train the SVM model\n",
        "svm_model = svm.SVC(kernel='linear', C=1.0)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# 5. Evaluate the model\n",
        "y_pred = svm_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5DAZCIMIDvi"
      },
      "outputs": [],
      "source": [
        "# Convert X_geospatial to a numpy array\n",
        "X_geospatial_array = np.array(X_geospatial)\n",
        "\n",
        "# Ensure X_image is already a numpy array\n",
        "\n",
        "# Check shapes\n",
        "print(\"X_image shape:\", X_image.shape)\n",
        "print(\"X_geospatial_array shape:\", X_geospatial_array.shape)\n",
        "\n",
        "# Reshape X_geospatial_array if necessary\n",
        "# Reshape it to have 39 rows and 1 column\n",
        "X_geospatial_array = X_geospatial_array.reshape(-1, 1)\n",
        "\n",
        "# Concatenate image and geospatial features\n",
        "X_combined = np.concatenate((X_image, X_geospatial_array), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWb0RZbWGKLP"
      },
      "outputs": [],
      "source": [
        "print( X_image[0:1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "t1fbnmGW948s"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Number of outliers replaced: []\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import zscore\n",
        "import numpy as np\n",
        "\n",
        "def replace_outliers_w_zero(gdf, threshold=1, null_object=np.nan):\n",
        "    \"\"\"\n",
        "    Replace outliers in a GeoDataFrame with a null object based on z-scores of latitude and longitude.\n",
        "\n",
        "    Parameters:\n",
        "    - gdf: GeoDataFrame with 'latitude' and 'longitude' columns.\n",
        "    - threshold: Z-score threshold for identifying outliers (default is 3).\n",
        "    - null_object: Value to replace outliers with (default is np.nan).\n",
        "\n",
        "    Returns:\n",
        "    - gdf_no_outliers: GeoDataFrame with outliers replaced by null_object.\n",
        "    - outliers: DataFrame containing the identified outliers.\n",
        "    - outliers_count: Number of outliers replaced.\n",
        "    \"\"\"\n",
        "    latitudes = gdf['latitude']\n",
        "    longitudes = gdf['longitude']\n",
        "\n",
        "    # Calculate z-scores for latitudes and longitudes\n",
        "    z_scores_lat = zscore(latitudes)\n",
        "    z_scores_lon = zscore(longitudes)\n",
        "\n",
        "    # Identify outliers based on either latitude or longitude\n",
        "    outliers_mask = (abs(z_scores_lat) > threshold) | (abs(z_scores_lon) > threshold)\n",
        "\n",
        "    # Create a copy of the GeoDataFrame to avoid modifying the original data\n",
        "    gdf_no_outliers = gdf.copy()\n",
        "\n",
        "    # Replace outliers with null_object\n",
        "    # gdf_no_outliers.loc[outliers_mask, ['latitude', 'longitude']] = 0\n",
        "\n",
        "    gdf_no_outliers['outlier'] = outliers_mask\n",
        "\n",
        "    # Create a DataFrame containing the identified outliers\n",
        "    outliers = gdf_no_outliers[outliers_mask]\n",
        "    gdf_remove_outliers = gdf_no_outliers[~outliers_mask]\n",
        "\n",
        "    # Count of outliers replaced\n",
        "    outliers_count = outliers_mask.sum()\n",
        "\n",
        "    return gdf_no_outliers, outliers, outliers_count\n",
        "\n",
        "def calculate_center_point(gdf):\n",
        "    \"\"\"\n",
        "    Calculate the center point based on the median latitude and longitude of a GeoDataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - gdf: GeoDataFrame with 'latitude' and 'longitude' columns.\n",
        "\n",
        "    Returns:\n",
        "    - center_point: Tuple containing the latitude and longitude of the center point.\n",
        "    - center_point_point: Shapely point of the center_point\n",
        "    \"\"\"\n",
        "\n",
        "    # Remove outliers from the original GeoDataFrame\n",
        "    gdf = gdf[gdf['outlier'] != True]\n",
        "    latitudes = gdf['latitude']\n",
        "    longitudes = gdf['longitude']\n",
        "\n",
        "\n",
        "    # Calculate the median of latitudes and longitudes\n",
        "    latitude_median = latitudes.median()\n",
        "    longitude_median = longitudes.median()\n",
        "\n",
        "    # Create a center point tuple\n",
        "    center_point = (latitude_median, longitude_median)\n",
        "    center_point_point = gdf.dissolve().centroid\n",
        "\n",
        "    return center_point, center_point_point\n",
        "\n",
        "def is_nearby(point, central_point, distance=lat_degrees*100):\n",
        "    value = point.distance(central_point) <= distance\n",
        "    # print(value)\n",
        "    return value\n",
        "\n",
        "outliers_counts = []\n",
        "groups = []\n",
        "groups_no_outliers = []\n",
        "\n",
        "# for location_id, group in ssid_gdf.groupby('LocationID'):\n",
        "#     print('calculating for', location_id)\n",
        "#     group_no_outliers, outliers, outliers_count = replace_outliers_w_zero(group)\n",
        "\n",
        "\n",
        "#     center_point, center_point_point = calculate_center_point(group_no_outliers)\n",
        "#     # print(center_point)\n",
        "#     group['nearby'] = group.apply(lambda row: is_nearby(row['geometry'],\n",
        "#                                                                     center_point_point), axis=1)\n",
        "\n",
        "#     G, vegetation_natural, landuse_natural, park_natural, water_natural, wetland_natural, tree_natural, buildings_osm = load_data_for_center_point(center_point)\n",
        "#     edges_gdf = preprocess_street_network(G)\n",
        "\n",
        "#     for index, row in group.iterrows():\n",
        "#         print('Processing data for Point', index, 'in',  row['LocationID'])\n",
        "#         #create stuff per point\n",
        "#         point_row =  (row['latitude'], row['longitude'])\n",
        "#         bounding_box, bbox_coordinates = get_bounding_box(point_row, distance)\n",
        "#         scalebar_polygons, scale_coordinates  = create_scale_bar(bbox_coordinates, point_row, meters = 4)\n",
        "#         multipolygon_radius = create_radius_from_bbox(point_row, bounding_box, distance)\n",
        "#         # check if the point is nearby\n",
        "#         if row['nearby'] is True:\n",
        "#             point_row =  (row['latitude'], row['longitude'])\n",
        "#             # Plotting\n",
        "#             plot_from_multiple_points(index, G, edges_gdf, buildings_osm, park_natural, landuse_natural,\n",
        "#                                   water_natural, wetland_natural, tree_natural, point_row,\n",
        "#                                   scalebar_polygons, multipolygon_radius,\n",
        "#                                   fig_size=[10,10], dpi=600, bbox=bbox_coordinates)\n",
        "#         else:\n",
        "#             point_row =  (row['latitude'], row['longitude'])\n",
        "#             center_point = point_row\n",
        "#             G_temp, vegetation_temp, landuse_temp, park_temp, wate_temp, wetland_temp, tree_temp, buildings_osm_temp = load_data_for_center_point(center_point)\n",
        "#             edges_gdf_temp = preprocess_street_network(G_temp)\n",
        "#             plot_from_multiple_points(index, G_temp, edges_gdf_temp, buildings_osm_temp, park_temp, landuse_temp,\n",
        "#                                   water_temp, wetland_temp, tree_temp, point_row,\n",
        "#                                   scalebar_polygons, multipolygon_radius,\n",
        "#                                   fig_size=[10,10], dpi=600, bbox=bbox_coordinates)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#     outliers_counts.append(outliers_count)\n",
        "#     groups.append(group)\n",
        "#     groups_no_outliers.append(group_no_outliers)\n",
        "\n",
        "\n",
        "# Print the number of outliers removed\n",
        "print(f\"\\nNumber of outliers replaced: {outliers_counts}\")\n",
        "\n",
        "# # Print the outliers\n",
        "# print(\"Outliers:\")\n",
        "# print(outliers)\n",
        "# group_no_outliers = groups_no_outliers[0]\n",
        "# group_no_outliers[group_no_outliers['outlier'] == True]\n",
        "# group01 = groups[7]\n",
        "# group01[group01['nearby'] == False]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "LocationID = \"Location123\"\n",
        "index = 1\n",
        "\n",
        "# Construct the filename string\n",
        "filename = f\"{LocationID}_plot_{index}.png\"\n",
        "\n",
        "# Save the plot to the specified folder with the constructed filename\n",
        "plt.savefig(r'C:/Users/n.smit/OneDrive - Oosterhoff Group/Documents/Master Thesis/DATA/plot_maps/' + filename)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def process_location_data(ssid_gdf, distance=100):\n",
        "    outliers_counts = []\n",
        "    groups = []\n",
        "    groups_no_outliers = []\n",
        "\n",
        "    for location_id, group in ssid_gdf.groupby('LocationID'):\n",
        "        print(f'Calculating for Location ID: {location_id}')\n",
        "\n",
        "        # Replace outliers with zero\n",
        "        group_no_outliers, outliers, outliers_count = replace_outliers_w_zero(group)\n",
        "        outliers_counts.append(outliers_count)\n",
        "        groups.append(group)\n",
        "        groups_no_outliers.append(group_no_outliers)\n",
        "\n",
        "        # Calculate center point\n",
        "        center_point, center_point_point = calculate_center_point(group_no_outliers)\n",
        "\n",
        "        # Assign 'nearby' flag\n",
        "        group['nearby'] = group.apply(lambda row: is_nearby(row['geometry'], center_point_point), axis=1)\n",
        "\n",
        "        # Load data for center point and preprocess street network\n",
        "        G, vegetation_natural, landuse_natural, park_natural, water_natural, wetland_natural, tree_natural, buildings_osm = load_data_for_center_point(center_point, distance*1.5)\n",
        "        edges_gdf = preprocess_street_network(G)\n",
        "\n",
        "        for index, row in group.iterrows():\n",
        "            print(f'Processing data for Point {index} in {row[\"LocationID\"]}')\n",
        "            \n",
        "            # Create data structures per point\n",
        "            point_row = (row['latitude'], row['longitude'])\n",
        "            bounding_box, bbox_coordinates = get_bounding_box(point_row, distance)\n",
        "            scalebar_polygons, scale_coordinates = create_scale_bar(bbox_coordinates, point_row, meters=4)\n",
        "            multipolygon_radius = create_radius_from_bbox(point_row, bounding_box, distance)\n",
        "            # text = (f'point {index} in {row[\"LocationID\"]}')\n",
        "            # text_map = plt.text(bbox_coordinates[0], bbox_coordinates[2], text)\n",
        "\n",
        "            # Check if the point is nearby\n",
        "            if row['nearby']:\n",
        "                # Plotting for nearby points\n",
        "                plot_from_multiple_points(index, G, edges_gdf, buildings_osm, park_natural, landuse_natural,\n",
        "                                          water_natural, wetland_natural, tree_natural, point_row,\n",
        "                                          scalebar_polygons, multipolygon_radius, #text,\n",
        "                                          fig_size=[10, 10], dpi=600, bbox=bbox_coordinates)\n",
        "            else:\n",
        "                # Load data for center point and preprocess street network for distant points\n",
        "                center_point = point_row\n",
        "                G_temp, vegetation_temp, landuse_temp, park_temp, water_temp, wetland_temp, tree_temp, buildings_osm_temp = load_data_for_center_point(center_point, distance)\n",
        "                edges_gdf_temp = preprocess_street_network(G_temp)\n",
        "                \n",
        "                # Plotting for distant points\n",
        "                plot_from_multiple_points(index, G_temp, edges_gdf_temp, buildings_osm_temp, park_temp, landuse_temp,\n",
        "                                          water_temp, wetland_temp, tree_temp, point_row,\n",
        "                                          scalebar_polygons, multipolygon_radius, #text,\n",
        "                                          fig_size=[10, 10], dpi=600, bbox=bbox_coordinates)\n",
        "\n",
        "    return outliers_counts, groups, groups_no_outliers\n",
        "\n",
        "\n",
        "ssid_gdf_plotting01 = process_location_data(ssid_gdf, distance=100)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "d23vTVQ-XKAM"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
